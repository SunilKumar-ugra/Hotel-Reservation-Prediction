{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config/path_config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config/path_config.py\n",
    "\n",
    "####################### MODEL TRAINING #################\n",
    "\n",
    "MODEL_OUTPUT_PATH = \"artifacts/models/lgbm_model.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config/model_params.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config/model_params.py\n",
    "from scipy.stats import randint,uniform\n",
    "\n",
    "LIGHTGM_PARAMS={\n",
    "    'n_estimators':randint(100,500),\n",
    "    'max_depth' : randint(5,50),\n",
    "    'learning_rate': uniform(0.01,0.2),\n",
    "    'num_leaves': randint(20,100),\n",
    "    'boosting_type' : ['gbdt' , 'dart' , 'goss']\n",
    "}\n",
    "\n",
    "\n",
    "RANDOM_SEARCH_PARAMS = {\n",
    "    'n_iter' : 2,\n",
    "    'cv' : 2,\n",
    "    'n_jobs':-1,\n",
    "    'verbose' :2,\n",
    "    'random_state' : 42,\n",
    "    'scoring' : 'accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to src/model_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a src/model_training.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from src.logger import get_logger\n",
    "from src.custom_exception import CustomException\n",
    "from config.paths_config import *\n",
    "from config.model_params import *\n",
    "from utils.common_functions import read_yaml,load_data\n",
    "from scipy.stats import randint\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to src/model_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a src/model_training.py\n",
    "\n",
    "class ModelTraining:\n",
    "\n",
    "    def __init__(self,train_path,test_path,model_output_path):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.model_output_path = model_output_path\n",
    "\n",
    "        self.params_dist = LIGHTGM_PARAMS\n",
    "        self.random_search_params = RANDOM_SEARCH_PARAMS\n",
    "\n",
    "    def load_and_split_data(self):\n",
    "        try:\n",
    "            logger.info(f\"Loading data from {self.train_path}\")\n",
    "            train_df = load_data(self.train_path)\n",
    "\n",
    "            logger.info(f\"Loading data from {self.test_path}\")\n",
    "            test_df = load_data(self.test_path)\n",
    "\n",
    "            X_train = train_df.drop(columns=[\"booking_status\"])\n",
    "            y_train = train_df[\"booking_status\"]\n",
    "\n",
    "            X_test = test_df.drop(columns=[\"booking_status\"])\n",
    "            y_test = test_df[\"booking_status\"]\n",
    "\n",
    "            logger.info(\"Data splitted sucefully for Model Training\")\n",
    "\n",
    "            return X_train,y_train,X_test,y_test\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error while loading data {e}\")\n",
    "            raise CustomException(\"Failed to load data\" ,  e)\n",
    "        \n",
    "    def train_lgbm(self,X_train,y_train):\n",
    "        try:\n",
    "            logger.info(\"Intializing our model\")\n",
    "\n",
    "            lgbm_model = lgb.LGBMClassifier(random_state=self.random_search_params[\"random_state\"])\n",
    "\n",
    "            logger.info(\"Starting our Hyperparamter tuning\")\n",
    "\n",
    "            random_search = RandomizedSearchCV(\n",
    "                estimator=lgbm_model,\n",
    "                param_distributions=self.params_dist,\n",
    "                n_iter = self.random_search_params[\"n_iter\"],\n",
    "                cv = self.random_search_params[\"cv\"],\n",
    "                n_jobs=self.random_search_params[\"n_jobs\"],\n",
    "                verbose=self.random_search_params[\"verbose\"],\n",
    "                random_state=self.random_search_params[\"random_state\"],\n",
    "                scoring=self.random_search_params[\"scoring\"]\n",
    "            )\n",
    "\n",
    "            logger.info(\"Starting our Hyperparamter tuning\")\n",
    "\n",
    "            random_search.fit(X_train,y_train)\n",
    "\n",
    "            logger.info(\"Hyperparamter tuning completed\")\n",
    "\n",
    "            best_params = random_search.best_params_\n",
    "            best_lgbm_model = random_search.best_estimator_\n",
    "\n",
    "            logger.info(f\"Best paramters are : {best_params}\")\n",
    "\n",
    "            return best_lgbm_model\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error while training model {e}\")\n",
    "            raise CustomException(\"Failed to train model\" ,  e)\n",
    "    \n",
    "    def evaluate_model(self , model , X_test , y_test):\n",
    "        try:\n",
    "            logger.info(\"Evaluating our model\")\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            accuracy = accuracy_score(y_test,y_pred)\n",
    "            precision = precision_score(y_test,y_pred)\n",
    "            recall = recall_score(y_test,y_pred)\n",
    "            f1 = f1_score(y_test,y_pred)\n",
    "\n",
    "            logger.info(f\"Accuracy Score : {accuracy}\")\n",
    "            logger.info(f\"Precision Score : {precision}\")\n",
    "            logger.info(f\"Recall Score : {recall}\")\n",
    "            logger.info(f\"F1 Score : {f1}\")\n",
    "\n",
    "            return {\n",
    "                \"accuracy\" : accuracy,\n",
    "                \"precison\" : precision,\n",
    "                \"recall\" : recall,\n",
    "                \"f1\" : f1\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error while evaluating model {e}\")\n",
    "            raise CustomException(\"Failed to evaluate model\" ,  e)\n",
    "        \n",
    "    def save_model(self,model):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(self.model_output_path),exist_ok=True)\n",
    "\n",
    "            logger.info(\"saving the model\")\n",
    "            joblib.dump(model , self.model_output_path)\n",
    "            logger.info(f\"Model saved to {self.model_output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error while saving model {e}\")\n",
    "            raise CustomException(\"Failed to save model\" ,  e)\n",
    "    \n",
    "    def run(self):\n",
    "        try:\n",
    "            with mlflow.start_run():\n",
    "                logger.info(\"Starting our Model Training pipeline\")\n",
    "\n",
    "                logger.info(\"Starting our MLFLOW experimentation\")\n",
    "\n",
    "                logger.info(\"Logging the training and testing datset to MLFLOW\")\n",
    "                mlflow.log_artifact(self.train_path , artifact_path=\"datasets\")\n",
    "                mlflow.log_artifact(self.test_path , artifact_path=\"datasets\")\n",
    "\n",
    "                X_train,y_train,X_test,y_test =self.load_and_split_data()\n",
    "                best_lgbm_model = self.train_lgbm(X_train,y_train)\n",
    "                metrics = self.evaluate_model(best_lgbm_model ,X_test , y_test)\n",
    "                self.save_model(best_lgbm_model)\n",
    "\n",
    "                logger.info(\"Logging the model into MLFLOW\")\n",
    "                mlflow.log_artifact(self.model_output_path)\n",
    "\n",
    "                logger.info(\"Logging Params and metrics to MLFLOW\")\n",
    "                mlflow.log_params(best_lgbm_model.get_params())\n",
    "                mlflow.log_metrics(metrics)\n",
    "\n",
    "                logger.info(\"Model Training sucesfullly completed\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in model training pipeline {e}\")\n",
    "            raise CustomException(\"Failed during model training pipeline\" ,  e)\n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    trainer = ModelTraining(PROCESSED_TRAIN_DATA_PATH,PROCESSED_TEST_DATA_PATH,MODEL_OUTPUT_PATH)\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to pipeline/traing_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a pipeline/traing_pipeline.py  \n",
    "\n",
    "\n",
    "    ### 3. Model Training\n",
    "    from src.model_training import ModelTraining\n",
    "    trainer = ModelTraining(PROCESSED_TRAIN_DATA_PATH,PROCESSED_TEST_DATA_PATH,MODEL_OUTPUT_PATH)\n",
    "    trainer.run()\n",
    "    ################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hotel_reserv_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
