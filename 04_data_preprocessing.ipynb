{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config/config.yaml\n",
    "\n",
    "data_processing:\n",
    "  categorical_columns:\n",
    "    - type_of_meal_plan\n",
    "    - required_car_parking_space\n",
    "    - room_type_reserved\n",
    "    - market_segment_type\n",
    "    - repeated_guest\n",
    "    - booking_status\n",
    "  numerical_columns:\n",
    "    - no_of_adults\n",
    "    - no_of_children\n",
    "    - no_of_weekend_nights\n",
    "    - no_of_week_nights\n",
    "    - lead_time\n",
    "    - arrival_year\n",
    "    - arrival_month\n",
    "    - arrival_date\n",
    "    - no_of_previous_cancellations\n",
    "    - no_of_previous_bookings_not_canceled\n",
    "    - avg_price_per_room\n",
    "    - no_of_special_requests\n",
    "  skewness_threshold : 5\n",
    "  no_of_features : 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config/path_config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config/path_config.py\n",
    "\n",
    "######################## DATA PROCESSING ########################\n",
    "\n",
    "PROCESSED_DIR = \"artifacts/processed\"\n",
    "PROCESSED_TRAIN_DATA_PATH = os.path.join(PROCESSED_DIR,\"processed_train.csv\")\n",
    "PROCESSED_TEST_DATA_PATH = os.path.join(PROCESSED_DIR,\"processed_test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data PreProcessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to src/data_preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a src/data_preprocessing.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.logger import get_logger\n",
    "from src.custom_exception import CustomException\n",
    "from config.paths_config import *\n",
    "from utils.common_functions import read_yaml,load_data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to src/data_preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a src/data_preprocessing.py\n",
    "class DataProcessor:\n",
    "\n",
    "    def __init__(self, train_path, test_path, processed_dir, config_path):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.processed_dir = processed_dir\n",
    "\n",
    "        self.config = read_yaml(config_path)\n",
    "\n",
    "        if not os.path.exists(self.processed_dir):\n",
    "            os.makedirs(self.processed_dir)\n",
    "        \n",
    "    \n",
    "    def preprocess_data(self,df):\n",
    "        try:\n",
    "            logger.info(\"Starting our Data Processing step\")\n",
    "\n",
    "            logger.info(\"Dropping the columns\")\n",
    "            df.drop(columns=['Unnamed: 0', 'Booking_ID'] , inplace=True)\n",
    "            df.drop_duplicates(inplace=True)\n",
    "\n",
    "            cat_cols = self.config[\"data_processing\"][\"categorical_columns\"]\n",
    "            num_cols = self.config[\"data_processing\"][\"numerical_columns\"]\n",
    "\n",
    "            logger.info(\"Applying Label Encoding\")\n",
    "\n",
    "            label_encoder = LabelEncoder()\n",
    "            mappings={}\n",
    "\n",
    "            for col in cat_cols:\n",
    "                df[col] = label_encoder.fit_transform(df[col])\n",
    "                mappings[col] = {label:code for label,code in zip(label_encoder.classes_ , label_encoder.transform(label_encoder.classes_))}\n",
    "\n",
    "            logger.info(\"Label Mappings are : \")\n",
    "            for col,mapping in mappings.items():\n",
    "                logger.info(f\"{col} : {mapping}\")\n",
    "\n",
    "            logger.info(\"Doing Skewness HAndling\")\n",
    "\n",
    "            skew_threshold = self.config[\"data_processing\"][\"skewness_threshold\"]\n",
    "            skewness = df[num_cols].apply(lambda x:x.skew())\n",
    "\n",
    "            for column in skewness[skewness>skew_threshold].index:\n",
    "                df[column] = np.log1p(df[column])\n",
    "\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during preprocess step {e}\")\n",
    "            raise CustomException(\"Error while preprocess data\", e)\n",
    "        \n",
    "    def balance_data(self,df):\n",
    "        try:\n",
    "            logger.info(\"Handling Imbalanced Data\")\n",
    "            X = df.drop(columns='booking_status')\n",
    "            y = df[\"booking_status\"]\n",
    "\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_resampled , y_resampled = smote.fit_resample(X,y)\n",
    "\n",
    "            balanced_df = pd.DataFrame(X_resampled , columns=X.columns)\n",
    "            balanced_df[\"booking_status\"] = y_resampled\n",
    "\n",
    "            logger.info(\"Data balanced sucesffuly\")\n",
    "            return balanced_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during balancing data step {e}\")\n",
    "            raise CustomException(\"Error while balancing data\", e)\n",
    "    \n",
    "    def select_features(self,df):\n",
    "        try:\n",
    "            logger.info(\"Starting our Feature selection step\")\n",
    "\n",
    "            X = df.drop(columns='booking_status')\n",
    "            y = df[\"booking_status\"]\n",
    "\n",
    "            model =  RandomForestClassifier(random_state=42)\n",
    "            model.fit(X,y)\n",
    "\n",
    "            feature_importance = model.feature_importances_\n",
    "\n",
    "            feature_importance_df = pd.DataFrame({\n",
    "                        'feature':X.columns,\n",
    "                        'importance':feature_importance\n",
    "                            })\n",
    "            top_features_importance_df = feature_importance_df.sort_values(by=\"importance\" , ascending=False)\n",
    "\n",
    "            num_features_to_select = self.config[\"data_processing\"][\"no_of_features\"]\n",
    "\n",
    "            top_10_features = top_features_importance_df[\"feature\"].head(num_features_to_select).values\n",
    "\n",
    "            logger.info(f\"Features selected : {top_10_features}\")\n",
    "\n",
    "            top_10_df = df[top_10_features.tolist() + [\"booking_status\"]]\n",
    "\n",
    "            logger.info(\"Feature slection completed sucesfully\")\n",
    "\n",
    "            return top_10_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during feature selection step {e}\")\n",
    "            raise CustomException(\"Error while feature selection\", e)\n",
    "    \n",
    "    def save_data(self,df , file_path):\n",
    "        try:\n",
    "            logger.info(\"Saving our data in processed folder\")\n",
    "\n",
    "            df.to_csv(file_path, index=False)\n",
    "\n",
    "            logger.info(f\"Data saved sucesfuly to {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during saving data step {e}\")\n",
    "            raise CustomException(\"Error while saving data\", e)\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            logger.info(\"Loading data from RAW directory\")\n",
    "\n",
    "            train_df = load_data(self.train_path)\n",
    "            test_df = load_data(self.test_path)\n",
    "\n",
    "            train_df = self.preprocess_data(train_df)\n",
    "            test_df = self.preprocess_data(test_df)\n",
    "\n",
    "            train_df = self.balance_data(train_df)\n",
    "            test_df = self.balance_data(test_df)\n",
    "\n",
    "            train_df = self.select_features(train_df)\n",
    "            test_df = test_df[train_df.columns]  \n",
    "\n",
    "            self.save_data(train_df,PROCESSED_TRAIN_DATA_PATH)\n",
    "            self.save_data(test_df , PROCESSED_TEST_DATA_PATH)\n",
    "\n",
    "            logger.info(\"Data processing completed sucesfully\")    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during preprocessing pipeline {e}\")\n",
    "            raise CustomException(\"Error while data preprocessing pipeline\", e)\n",
    "              \n",
    "    \n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    processor = DataProcessor(TRAIN_FILE_PATH,TEST_FILE_PATH,PROCESSED_DIR,CONFIG_PATH)\n",
    "    processor.process()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to pipeline/traing_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a pipeline/traing_pipeline.py    \n",
    "    ### 2. Data Processing\n",
    "    from src.data_preprocessing import DataProcessor\n",
    "    processor = DataProcessor(TRAIN_FILE_PATH,TEST_FILE_PATH,PROCESSED_DIR,CONFIG_PATH)\n",
    "    processor.process()\n",
    "    ####################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hotel_reserv_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
